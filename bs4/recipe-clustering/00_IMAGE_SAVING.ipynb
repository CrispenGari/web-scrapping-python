{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd165074-1034-43b3-9d37-e0ba83b31318",
   "metadata": {},
   "source": [
    "### Image Scraping\n",
    "\n",
    "In this notebook we are going to scrape images of food recipes. We are going to get the image urls from the recipe files `.json` file that can be found on my gist repository at [this](https://gist.github.com/CrispenGari/794a10de80b0bc3f5ff3a7b99ebb88de). \n",
    "\n",
    "\n",
    "Let's first import all the required packages that we are going to use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dda44664-40ac-4498-8112-b9f71804219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import uuid\n",
    "import tqdm\n",
    "import json\n",
    "import multiprocessing\n",
    "import shutil\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfceee36-5183-4b60-880b-1723764ab2fa",
   "metadata": {},
   "source": [
    "The next thing is to define file path for where we are going to load our recipe file from and where we are going to save our images to. Our recipe files are located in the `data` folder and we are going to save our images in the `recipe_images` folder with a file name generated by `uuid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc7deadf-ae35-4966-b3cc-2f1a1984eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "save_path = 'recipe_images'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "    \n",
    "assert os.path.exists(data_path), f\"The path '{data_path}' does not exists.\"\n",
    "assert os.path.exists(save_path), f\"The path '{save_path}' does not exists.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbfe4a1-0bb2-453a-9d35-5478b4d6824e",
   "metadata": {},
   "source": [
    "Next we are going to load all the `json` files and image urls for each recipe and put them in a list.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "009a6788-c556-4e94-b70a-c9cd8af0e59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading...: 100%|████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 36.77it/s]\n"
     ]
    }
   ],
   "source": [
    "images_urls = list()\n",
    "for file in tqdm.tqdm(os.listdir(data_path), desc=\"loading...\"):\n",
    "    with open(os.path.join(data_path, file)) as f:\n",
    "        data = json.loads(f.read())\n",
    "        for recipe in data:\n",
    "            images_urls.append(recipe.get('image'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39a573a-c784-4a24-8a93-9ad93f8720d5",
   "metadata": {},
   "source": [
    "The `save_image` file bellow takes in a url and save an image in the  `recipe_images` folder with a unique file name. We are also going to keep in track of the skipped images because of network issues so that we will try to save them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ecadfd-06e8-4a2b-9e9c-db71feb91b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped = list()\n",
    "def save_image(url):\n",
    "    try:\n",
    "        image_name = f\"{str(uuid.uuid4())}.{url.split('.')[-1]}\"\n",
    "        data = requests.get(url).content\n",
    "        save_name = os.path.join(save_path, image_name)\n",
    "        with open(save_name, 'wb') as fp:\n",
    "            fp.write(data)\n",
    "    except Exception:\n",
    "        skipped.append(url)\n",
    "        print(\"url skipped:\", url)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c46b3b-b62c-4d70-b486-c7d11442d392",
   "metadata": {},
   "source": [
    "Next we are then going to download the images and save them in the `recipe_images` folder. We are going to use the `ThreadPoolExecutor` from `concurrent.futures` to do multi-processing in downloading and saving the images concurrently. First let's check the number of `cpu's` that are in this computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97e6cfb0-7293-4223-be4f-39a5b6ef2807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPUs: 12\n"
     ]
    }
   ],
   "source": [
    "num_workers = multiprocessing.cpu_count()\n",
    "print(\"CPUs: {}\".format(num_workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3cd59-7c0c-4220-a92f-dc2c20d83158",
   "metadata": {},
   "source": [
    "Now we can download the images `concurrently` in the following code cell. We can alternatively use the following code:\n",
    "\n",
    "```py\n",
    "with multiprocessing.Pool(num_workers) as pool:\n",
    "    for _ in tqdm.tqdm(pool.imap_unordered(save_image, images_urls), total=len(images_urls), desc=\"downloading...\"):\n",
    "        pass\n",
    "print(\"Done!!\")\n",
    "```\n",
    "However this code only works when you wrap it in the `if __name__ == '__main__':` which means in python files mostly not in notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a975f9d3-2382-4d1c-8dc7-4c5a22a410fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading...:   8%|████▉                                                          | 235/3017 [02:57<34:16,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url skipped: https://images.immediate.co.uk/production/volatile/sites/30/2020/08/fun-cake-9735009.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading...:  17%|██████████▋                                                    | 512/3017 [06:17<22:39,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url skipped: https://images.immediate.co.uk/production/volatile/sites/30/2020/08/recipe-image-legacy-id-849607_11-aaaf1ea.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading...:  24%|███████████████▏                                               | 727/3017 [08:55<27:42,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url skipped: https://images.immediate.co.uk/production/volatile/sites/30/2021/03/Sausage-pasta-bake-f71108a.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading...:  49%|██████████████████████████████▍                               | 1479/3017 [17:58<10:49,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url skipped: https://images.immediate.co.uk/production/volatile/sites/30/2020/08/halloumi-with-lemony-lentil-salad-a57237c.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading...:  63%|███████████████████████████████████████▏                      | 1904/3017 [22:58<13:31,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url skipped: https://images.immediate.co.uk/production/volatile/sites/30/2020/08/epic-summer-salad-000aded.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading...:  63%|███████████████████████████████████████▏                      | 1906/3017 [22:59<11:59,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url skipped: https://images.immediate.co.uk/production/volatile/sites/30/2020/08/potato-salad-main-272de70.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading...: 100%|██████████████████████████████████████████████████████████████| 3017/3017 [32:14<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    futures = [executor.submit(save_image, url) for url in images_urls]\n",
    "    for future in tqdm.tqdm(as_completed(futures), total=len(images_urls), desc=\"downloading...\"):\n",
    "        pass\n",
    "\n",
    "print(\"Done!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe1b575-791e-4139-805c-2816c464cc51",
   "metadata": {},
   "source": [
    "Next we try to download the skipped images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aaaae45-1832-43d8-8454-50279fcc0fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading...:   0%|▏                                                                | 6/3017 [00:01<13:36,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    futures = [executor.submit(save_image, url) for url in skipped]\n",
    "    for future in tqdm.tqdm(as_completed(futures), total=len(skipped), desc=\"downloading...\"):\n",
    "        pass\n",
    "print(\"Done!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e201955-ae57-404b-92ac-54760ec4f0ee",
   "metadata": {},
   "source": [
    "Next we are going to create 2 folders in the `recipe_images` which are:\n",
    "\n",
    "1. `train`\n",
    "2. `test`\n",
    "\n",
    "And then we are going to split our images by taking `20%` of the images and put them in the `test` set and the remaining images will be moved in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48f33459-a3ac-408e-b449-a8f1a54e6dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Fraction:  603\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(save_path, 'train')\n",
    "test_path = os.path.join(save_path, 'test')\n",
    "\n",
    "if not os.path.exists(train_path):\n",
    "    os.mkdir(train_path)\n",
    "if not os.path.exists(test_path):\n",
    "    os.mkdir(test_path)\n",
    "\n",
    "test_fraction = int(.20 * len(os.listdir(save_path)))\n",
    "print(\"Test Fraction: \", test_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490a3e7a-3296-4ae7-8e1a-a193f8245a08",
   "metadata": {},
   "source": [
    "Next we are going to move the first `20%` of images into the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "840f3dfb-b78d-4263-9e9f-70ca902aa262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "moving to test directory...: 100%|███████████████████████████████████████████████████| 603/603 [00:11<00:00, 50.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def move(img, trg):\n",
    "    src = os.path.join(save_path, img)\n",
    "    if not os.path.isdir(src):\n",
    "        shutil.move(src, trg)\n",
    "    \n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    futures = [executor.submit(move, img, test_path) for img in os.listdir(save_path)[:test_fraction]]\n",
    "    for future in tqdm.tqdm(as_completed(futures), total=len(os.listdir(save_path)[:test_fraction]), desc=\"moving to test directory...\"):\n",
    "        pass\n",
    "print(\"Done!!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ac002b-5be8-4643-a2ad-171e493a6cf9",
   "metadata": {},
   "source": [
    "The rest of the images will be moved to the `train` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4f579e1-fc00-4862-b74a-d48fe9fc631c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "moving to train directory...: 2416it [00:54, 44.46it/s]                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    futures = [executor.submit(move, img, train_path) for img in os.listdir(save_path)]\n",
    "    for future in tqdm.tqdm(as_completed(futures), total=len(os.listdir(save_path)), desc=\"moving to train directory...\"):\n",
    "        pass\n",
    "print(\"Done!!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb5bb30-fafd-46d7-a406-3057d3cb4d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
