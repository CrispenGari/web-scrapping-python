{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d61b93e-6460-454f-a5e6-491826d68c06",
   "metadata": {},
   "source": [
    "### Image Dataset - `TickVrsMite`\n",
    "\n",
    "In this notebook we are going to scrape the data from [this site](https://www.insectimages.org/index.cfm) for an image classification dataset.\n",
    "\n",
    "### Innstallation\n",
    "\n",
    "First we need to install `selenium` if not installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81e6375b-18e8-43b7-b75e-2d082489beb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install selenium -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd622a-ef65-48e6-b974-21add0ab02e0",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Next we are going to import all the packages that we will use in this notebook for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "12903010-7b16-4967-ae9a-04a0dc10106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tqdm\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd2c5e-febc-476b-8895-09b0780da817",
   "metadata": {},
   "source": [
    "Next we are going to set the seed for random operations for reproducivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c32702b-4a38-4aba-acbc-725f8f55da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 23\n",
    "\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7d07f2-d0f3-466e-9e30-93db160e5a9f",
   "metadata": {},
   "source": [
    "Next we are going to create an instance of a Chrome driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ff9708ef-ae83-4141-b4a8-f07ffadfc77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.chrome.webdriver.WebDriver (session=\"130c802a10357cde800f972a1ed01e32\")>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71931edd-6011-4326-a3e1-e01d1d2ae175",
   "metadata": {},
   "source": [
    "We are then going to define the path to where we want to get the images of the insects from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "31f6adc7-0b2e-4f13-9ec0-23c36c0a0495",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_to_images ='https://www.insectimages.org/browse/taxthumb.cfm?order=131'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cf1231d2-79a3-430f-9960-524aeb74ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(urls_to_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bbad6f-7518-4084-b0b4-a60f33fd83aa",
   "metadata": {},
   "source": [
    "From the website the images are paginated so we need to do the infinite scrolling So the function:\n",
    "\n",
    "```py\n",
    "def scroll_down(driver, scroll_pause_time=1.0):\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(scroll_pause_time)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "scroll_down(driver, 20)\n",
    "```\n",
    "Is used to do the inifite automatic scrolling of the page using `selenium`.\n",
    "\n",
    "\n",
    "The following function will scrape a single page and returns us a list of dictionaries with `image` and `class` of the insect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e6281334-52c9-45ca-88a0-3170568bbd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(soup):\n",
    "    res = list()\n",
    "    img_container = soup.find('div', {'id': 'imagecontainer'})\n",
    "    for row in img_container.find_all('div', {'class': 'row vertical'}):\n",
    "        for item in row.find_all('div', {'class': 'pointer item text-center well'}):\n",
    "            try:\n",
    "                img = f\"https:{item.find('img')['src']}\"\n",
    "                class_ = item.find('div', {'class': 'img-foot'}).contents[0].split(' ')[-1].strip().lower()\n",
    "                res.append({'class': class_, 'image': img})\n",
    "            except Exception:\n",
    "                pass\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5ba29d-6712-48f5-9677-45ee31f881ac",
   "metadata": {},
   "source": [
    "We are going to define the number of pages we want to scroll  and start doing webscraping to get the images and their class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb1f92-8306-48cd-811f-3045f232c14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 24 for page 1...\n",
      "Got 48 for page 2...\n",
      "Got 72 for page 3...\n",
      "Got 95 for page 4...\n",
      "Got 119 for page 5...\n",
      "Got 138 for page 6...\n"
     ]
    }
   ],
   "source": [
    "number_of_pages = 900\n",
    "data = []\n",
    "for page in range(number_of_pages):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(10)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    res = scrape_page(soup)\n",
    "    data.extend(res)\n",
    "    print(f\"Got {len(res)} for page {page+1}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb6926-709e-4057-8c17-41ee7e521ba0",
   "metadata": {},
   "source": [
    "We can check the first `2` examples in the scrapped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05543146-f306-44f0-b6bd-864662cbc93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class': 'tick',\n",
       "  'image': 'https://bugwoodcloud.org/images/384x256/5626438.jpg'},\n",
       " {'class': 'mite',\n",
       "  'image': 'https://bugwoodcloud.org/images/384x256/5625783.jpg'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab01f5ad-b386-4bf7-a0e2-cf07716808a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349792"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e74f020-de31-4498-a9ac-bcef5db34638",
   "metadata": {},
   "source": [
    "In the following code cell we are going to create a dataframe based on the data that we have scrapped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aed47d1e-bf2b-4d09-b383-4b4ca87df548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tick</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/562643...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mite</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/562578...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/562537...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/562537...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/562537...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                              image\n",
       "0  tick  https://bugwoodcloud.org/images/384x256/562643...\n",
       "1  mite  https://bugwoodcloud.org/images/384x256/562578...\n",
       "2        https://bugwoodcloud.org/images/384x256/562537...\n",
       "3        https://bugwoodcloud.org/images/384x256/562537...\n",
       "4        https://bugwoodcloud.org/images/384x256/562537..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired = [list(r.values()) for r in data]\n",
    "\n",
    "df = pd.DataFrame(paired, columns=['class', 'image'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af04b9-2a84-4095-9c71-cd01f9b369a8",
   "metadata": {},
   "source": [
    "The following function will rename `plural`to `singular` for class names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "556b352c-c97d-41ed-a026-8950749554c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "mite           333379\n",
       "mites            7109\n",
       "tick             5705\n",
       "grapes           1171\n",
       "                 1019\n",
       "chiggers          676\n",
       "acari)            502\n",
       "ticks             179\n",
       "dermacentor        30\n",
       "parasitoid         22\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cbf6ccad-9cf8-46e9-be19-36a49ddf1fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_class(class_):\n",
    "    obj = {'ticks': 'tick', 'mites': 'mite'}\n",
    "    try:\n",
    "        return obj[class_]\n",
    "    except KeyError:\n",
    "        return class_\n",
    "df['class'] = df['class'].apply(rename_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a1c99185-a027-4379-97e9-db4ec6ccf038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tick', 'mite', '', 'chiggers', 'acari)', 'grapes', 'parasitoid',\n",
       "       'dermacentor'], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe01ae3a-4451-40a1-afe0-c6bee42692bc",
   "metadata": {},
   "source": [
    "Next we are going to drop the duplicates columns based on the `image` column and filter them to `2` labels for insects which is:\n",
    "\n",
    "1. `tick`\n",
    "2. `mite`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "692561dc-ac88-4a68-aa6e-71869c0d47ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "mite           3739\n",
       "tick            176\n",
       "grapes           20\n",
       "acari)           15\n",
       "                  6\n",
       "chiggers          4\n",
       "dermacentor       3\n",
       "parasitoid        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "40aaa9e8-31e7-4577-a7d7-dfbb9cd4823b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tick</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/562643...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mite</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/562578...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tick</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/561910...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tick</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/561909...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tick</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/561909...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                              image\n",
       "0  tick  https://bugwoodcloud.org/images/384x256/562643...\n",
       "1  mite  https://bugwoodcloud.org/images/384x256/562578...\n",
       "5  tick  https://bugwoodcloud.org/images/384x256/561910...\n",
       "6  tick  https://bugwoodcloud.org/images/384x256/561909...\n",
       "7  tick  https://bugwoodcloud.org/images/384x256/561909..."
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique = df.drop_duplicates(subset='image')\n",
    "df_filtered = df_unique[df_unique['class'].isin(['tick', 'mite'])]\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "451c8390-0d4d-4e0e-833d-3c17a9b531f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "df_filtered.to_csv('pickle.csv', index=False)\n",
    "print(\"Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eae3edec-3d07-472e-8d0c-6d421a017522",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = pd.read_csv('pickle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "23d14409-96a0-4698-848d-8ef57888a860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "mite    3739\n",
       "tick     176\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9075eeb3-1c16-476b-99ae-92ce2a798bef",
   "metadata": {},
   "source": [
    "Next we are going to download these images into their respective directories based on their class names. Before we donload them we want to make sure that they are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e95748e4-d3ec-4409-9cff-f27a51dcf338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "mite    176\n",
       "tick    176\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_size = df_filtered['class'].value_counts().min()\n",
    "df_balanced = df_filtered.groupby('class').apply(lambda x: x.sample(min_size)).reset_index(drop=True)\n",
    "df_balanced['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9feb2062-9543-47ae-abb6-0273c3faeacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"dataset\"\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "for class_ in ['tick', 'mite']:\n",
    "    class_dir = os.path.join(base_dir, class_)\n",
    "    if not os.path.exists(class_dir):\n",
    "        os.mkdir(class_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36325b-2c7f-49f6-9ce4-3e09113e40c3",
   "metadata": {},
   "source": [
    "We are going to use the `ThreadPoolExecutor` from `concurrent.futures` to do multi-processing in downloading and saving the images concurrently. First let's check the number of `cpu's` that are in this computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a3eea560-79cf-4b56-b68e-916962d6ec5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPUs: 12\n"
     ]
    }
   ],
   "source": [
    "num_workers = multiprocessing.cpu_count()\n",
    "print(\"CPUs: {}\".format(num_workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc2b842-003b-4504-b107-16e625ed6ec5",
   "metadata": {},
   "source": [
    "We can try to get the images and their classes from a pandas dataframe to a python list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "22054f72-546e-44ee-b554-355f40bbddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_urls = list(zip(\n",
    "    df_balanced['class'].values,\n",
    "    df_balanced['image'].values,\n",
    "))\n",
    "\n",
    "random.shuffle(img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "17e24058-4b75-48f0-b7b0-d98ca6dfa70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tick', 'https://bugwoodcloud.org/images/384x256/5488679.jpg'),\n",
       " ('tick', 'https://bugwoodcloud.org/images/384x256/5574613.jpg')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_urls[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e7436-6157-480f-a4ad-11df9c7ac1f1",
   "metadata": {},
   "source": [
    "The following function save a single image of an insect in it's respective folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "498ffcfa-8ed0-427f-a71f-163d1f522040",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped = list()\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "}\n",
    "\n",
    "def save_image(row):\n",
    "    class_, url = row\n",
    "    try:\n",
    "        image_name = f\"{url.split('/')[-1]}\"\n",
    "        res = requests.get(url, headers=headers)\n",
    "        if res.status_code == 200:\n",
    "            save_name = os.path.join(base_dir, class_, image_name)\n",
    "            with open(save_name, 'wb') as fp:\n",
    "                fp.write(res.content)\n",
    "        else:\n",
    "            print(\"Failed to download the image: STATUS CODE {}\".format(res.status_code))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"url skipped:\", url)\n",
    "        skipped.append(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8bdb26-cf63-4d9d-af2e-cee611430639",
   "metadata": {},
   "source": [
    "Next we are going to download the images from the urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b2a7f68b-a19a-4b15-b69c-93bddc50a87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352/352 [03:51<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    futures = [executor.submit(save_image, i) for i in img_urls]\n",
    "    for future in tqdm.tqdm(as_completed(futures), desc=\"downloading...\", total=len(img_urls)):\n",
    "        pass\n",
    "print(\"Done!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20423d-b42f-4987-bb79-a3c573c240a0",
   "metadata": {},
   "source": [
    "After downloading these images, We want to split our dataset into `2` sets the `train` and `test`. So we are going to create the following folder structure in our `dataset` directory.\n",
    "\n",
    "\n",
    "```\n",
    "ðŸ“ dataset\n",
    "    ðŸ“  train\n",
    "      ðŸ“class_1\n",
    "         - 0.jpg\n",
    "         - 1.jpg\n",
    "         ....\n",
    "      ðŸ“  class_2\n",
    "         - 0.jpg\n",
    "         - 1.jpg\n",
    "         ....\n",
    "      .....\n",
    "    ðŸ“  test\n",
    "      ðŸ“  class_1\n",
    "         - 0.jpg\n",
    "         - 1.jpg\n",
    "         ....\n",
    "      ðŸ“  class_2\n",
    "         - 0.jpg\n",
    "         - 1.jpg\n",
    "         ....\n",
    "    ....\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6ba53fcf-3491-4f66-9006-b859cdbff013",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_ in [\"tick\", \"mite\"]:\n",
    "    train_dir = os.path.join(base_dir,'train', class_)\n",
    "    test_dir = os.path.join(base_dir,'test', class_)\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152dc375-270c-4f82-ab76-d788a80863cf",
   "metadata": {},
   "source": [
    "We will take the first `72` images and put them in the test folder to the respective class and the rest will be taken to the train folder of the respective class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7c26431e-7ae8-464e-ac22-31a20f41a4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "moving images to the tick folder...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:00<00:00, 222.85it/s]\n",
      "moving images to the tick folder...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [00:00<00:00, 590.07it/s]\n",
      "moving images to the mite folder...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:00<00:00, 664.63it/s]\n",
      "moving images to the mite folder...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [00:00<00:00, 647.06it/s]\n"
     ]
    }
   ],
   "source": [
    "def move_to_final_destination(trg, class_:str, limit=None):\n",
    "    class_dir = os.path.join(base_dir, class_)\n",
    "    total = len(os.listdir(class_dir)) if limit is None else limit\n",
    "    if limit is None:\n",
    "        for image_name in tqdm.tqdm(os.listdir(class_dir), total=total, desc=f\"moving images to the {class_} folder...\"):\n",
    "            src = os.path.join(class_dir, image_name)\n",
    "            shutil.move(src, trg)\n",
    "    else:\n",
    "        for image_name in tqdm.tqdm(os.listdir(class_dir)[:limit], total=total, desc=f\"moving images to the {class_} folder...\"):\n",
    "            src = os.path.join(class_dir, image_name)\n",
    "            shutil.move(src, trg)\n",
    "\n",
    "for class_ in ['tick', 'mite']:\n",
    "    train_dir = os.path.join(base_dir,'train', class_)\n",
    "    test_dir = os.path.join(base_dir,'test', class_)\n",
    "    move_to_final_destination(test_dir, class_, limit=55)\n",
    "    move_to_final_destination(train_dir, class_, limit=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29108233-6e41-48a3-8e94-001ad139c54d",
   "metadata": {},
   "source": [
    "Next we are going to remove the `class` directories from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9c0d68fa-a756-43a1-954f-c3cf6a3b688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_ in ['tick', 'mite']:\n",
    "    _dir = os.path.join(base_dir, class_)\n",
    "    shutil.rmtree(_dir, 0o777)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e38000-ee75-4a8d-a313-cbfaa062f2f8",
   "metadata": {},
   "source": [
    "### Refs\n",
    "1. [github.com/CrispenGari](https://github.com/CrispenGari/web-scrapping-python/blob/main/selenium/selenium.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
