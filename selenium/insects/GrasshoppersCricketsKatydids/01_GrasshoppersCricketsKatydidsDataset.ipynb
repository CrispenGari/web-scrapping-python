{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d61b93e-6460-454f-a5e6-491826d68c06",
   "metadata": {},
   "source": [
    "### Image Dataset - `Grasshoppers, Crickets, and Katydids`\n",
    "\n",
    "In this notebook we are going to scrape the data from [this site](https://www.insectimages.org/index.cfm) for an image classification dataset.\n",
    "\n",
    "### Innstallation\n",
    "\n",
    "First we need to install `selenium` if not installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81e6375b-18e8-43b7-b75e-2d082489beb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install selenium -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd622a-ef65-48e6-b974-21add0ab02e0",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Next we are going to import all the packages that we will use in this notebook for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12903010-7b16-4967-ae9a-04a0dc10106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tqdm\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd2c5e-febc-476b-8895-09b0780da817",
   "metadata": {},
   "source": [
    "Next we are going to set the seed for random operations for reproducivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c32702b-4a38-4aba-acbc-725f8f55da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 23\n",
    "\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7d07f2-d0f3-466e-9e30-93db160e5a9f",
   "metadata": {},
   "source": [
    "Next we are going to create an instance of a Chrome driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9708ef-ae83-4141-b4a8-f07ffadfc77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.chrome.webdriver.WebDriver (session=\"b7e62b998fc3dd857cd74fc0a8d2785c\")>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71931edd-6011-4326-a3e1-e01d1d2ae175",
   "metadata": {},
   "source": [
    "We are then going to define the path to where we want to get the images of the insects from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f6adc7-0b2e-4f13-9ec0-23c36c0a0495",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_to_images ='https://www.insectimages.org/browse/taxthumb.cfm?order=159'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf1231d2-79a3-430f-9960-524aeb74ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(urls_to_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bbad6f-7518-4084-b0b4-a60f33fd83aa",
   "metadata": {},
   "source": [
    "From the website the images are paginated so we need to do the infinite scrolling So the function:\n",
    "\n",
    "```py\n",
    "def scroll_down(driver, scroll_pause_time=1.0):\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(scroll_pause_time)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "scroll_down(driver, 20)\n",
    "```\n",
    "Is used to do the inifite automatic scrolling of the page using `selenium`.\n",
    "\n",
    "\n",
    "The following function will scrape a single page and returns us a list of dictionaries with `image` and `class` of the insect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6281334-52c9-45ca-88a0-3170568bbd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(soup):\n",
    "    res = list()\n",
    "    img_container = soup.find('div', {'id': 'imagecontainer'})\n",
    "    for row in img_container.find_all('div', {'class': 'row vertical'}):\n",
    "        for item in row.find_all('div', {'class': 'pointer item text-center well'}):\n",
    "            try:\n",
    "                img = f\"https:{item.find('img')['src']}\"\n",
    "                class_ = item.find('div', {'class': 'img-foot'}).contents[0].split(' ')[-1].strip().lower()\n",
    "                res.append({'class': class_, 'image': img})\n",
    "            except Exception:\n",
    "                pass\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5ba29d-6712-48f5-9677-45ee31f881ac",
   "metadata": {},
   "source": [
    "We are going to define the number of pages we want to scroll  and start doing webscraping to get the images and their class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5eb1f92-8306-48cd-811f-3045f232c14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 216 for page 1...\n",
      "Got 240 for page 2...\n",
      "Got 264 for page 3...\n",
      "Got 288 for page 4...\n",
      "Got 312 for page 5...\n",
      "Got 336 for page 6...\n",
      "Got 360 for page 7...\n",
      "Got 384 for page 8...\n",
      "Got 408 for page 9...\n",
      "Got 432 for page 10...\n",
      "Got 456 for page 11...\n",
      "Got 480 for page 12...\n",
      "Got 504 for page 13...\n",
      "Got 528 for page 14...\n",
      "Got 552 for page 15...\n",
      "Got 576 for page 16...\n",
      "Got 600 for page 17...\n",
      "Got 624 for page 18...\n",
      "Got 648 for page 19...\n",
      "Got 672 for page 20...\n",
      "Got 696 for page 21...\n",
      "Got 720 for page 22...\n",
      "Got 744 for page 23...\n",
      "Got 768 for page 24...\n",
      "Got 792 for page 25...\n",
      "Got 816 for page 26...\n",
      "Got 840 for page 27...\n",
      "Got 864 for page 28...\n",
      "Got 888 for page 29...\n",
      "Got 912 for page 30...\n",
      "Got 936 for page 31...\n",
      "Got 960 for page 32...\n",
      "Got 984 for page 33...\n",
      "Got 1008 for page 34...\n",
      "Got 1032 for page 35...\n",
      "Got 1056 for page 36...\n",
      "Got 1080 for page 37...\n",
      "Got 1104 for page 38...\n",
      "Got 1128 for page 39...\n",
      "Got 1152 for page 40...\n",
      "Got 1176 for page 41...\n",
      "Got 1200 for page 42...\n",
      "Got 1224 for page 43...\n",
      "Got 1248 for page 44...\n",
      "Got 1272 for page 45...\n",
      "Got 1296 for page 46...\n",
      "Got 1320 for page 47...\n",
      "Got 1344 for page 48...\n",
      "Got 1368 for page 49...\n",
      "Got 1392 for page 50...\n",
      "Got 1416 for page 51...\n",
      "Got 1440 for page 52...\n",
      "Got 1464 for page 53...\n",
      "Got 1464 for page 54...\n",
      "Got 1464 for page 55...\n",
      "Got 1512 for page 56...\n",
      "Got 1536 for page 57...\n",
      "Got 1560 for page 58...\n",
      "Got 1584 for page 59...\n",
      "Got 1608 for page 60...\n",
      "Got 1622 for page 61...\n",
      "Got 1622 for page 62...\n",
      "Got 1622 for page 63...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_of_pages):\n\u001b[0;32m      4\u001b[0m     driver\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow.scrollTo(0, document.body.scrollHeight);\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      6\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m     res \u001b[38;5;241m=\u001b[39m scrape_page(soup)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "number_of_pages = 100\n",
    "data = []\n",
    "for page in range(number_of_pages):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(10)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    res = scrape_page(soup)\n",
    "    data.extend(res)\n",
    "    print(f\"Got {len(res)} for page {page+1}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb6926-709e-4057-8c17-41ee7e521ba0",
   "metadata": {},
   "source": [
    "We can check the first `2` examples in the scrapped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05543146-f306-44f0-b6bd-864662cbc93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class': 'katydid',\n",
       "  'image': 'https://bugwoodcloud.org/images/384x256/9009025.jpg'},\n",
       " {'class': 'katydid',\n",
       "  'image': 'https://bugwoodcloud.org/images/384x256/9009024.jpg'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab01f5ad-b386-4bf7-a0e2-cf07716808a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60114"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e74f020-de31-4498-a9ac-bcef5db34638",
   "metadata": {},
   "source": [
    "In the following code cell we are going to create a dataframe based on the data that we have scrapped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aed47d1e-bf2b-4d09-b383-4b4ca87df548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>katydid</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/900902...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>katydid</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/900902...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>katydid</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/900900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grasshopper</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/562780...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grasshopper</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/562780...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class                                              image\n",
       "0      katydid  https://bugwoodcloud.org/images/384x256/900902...\n",
       "1      katydid  https://bugwoodcloud.org/images/384x256/900902...\n",
       "2      katydid  https://bugwoodcloud.org/images/384x256/900900...\n",
       "3  grasshopper  https://bugwoodcloud.org/images/384x256/562780...\n",
       "4  grasshopper  https://bugwoodcloud.org/images/384x256/562780..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired = [list(r.values()) for r in data]\n",
    "\n",
    "df = pd.DataFrame(paired, columns=['class', 'image'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af04b9-2a84-4095-9c71-cd01f9b369a8",
   "metadata": {},
   "source": [
    "The following function will rename `plural`to `singular` for class names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbf6ccad-9cf8-46e9-be19-36a49ddf1fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_class(class_):\n",
    "    obj = {'katydids': 'katydid', 'grasshoppers': 'grasshopper', 'grashoppers': 'grasshopper',\n",
    "           'crickets': 'cricket', 'grasshoppper' :'grasshopper',\n",
    "          }\n",
    "    try:\n",
    "        return obj[class_]\n",
    "    except KeyError:\n",
    "        return class_\n",
    "df['class'] = df['class'].apply(rename_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1c99185-a027-4379-97e9-db4ec6ccf038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['katydid', 'grasshopper', 'cricket', 'locust', 'bush-cricket',\n",
       "       'acrididae)', 'boopie', 'subfamily)', 'conehead', 'grasshopper,',\n",
       "       'wetas', 'weta', 'gomphocerinae)'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe01ae3a-4451-40a1-afe0-c6bee42692bc",
   "metadata": {},
   "source": [
    "Next we are going to drop the duplicates columns based on the `image` column and filter them to `3` labels for insects which is:\n",
    "\n",
    "1. `grasshopper`\n",
    "2. `cricket`\n",
    "3. `katydids`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "692561dc-ac88-4a68-aa6e-71869c0d47ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "grasshopper       1093\n",
       "cricket            271\n",
       "katydid            155\n",
       "locust              30\n",
       "weta                25\n",
       "conehead            11\n",
       "wetas                9\n",
       "bush-cricket         7\n",
       "boopie               7\n",
       "subfamily)           6\n",
       "acrididae)           4\n",
       "gomphocerinae)       3\n",
       "grasshopper,         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40aaa9e8-31e7-4577-a7d7-dfbb9cd4823b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>katydid</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/900902...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>katydid</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/900902...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>katydid</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/900900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grasshopper</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/562780...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grasshopper</td>\n",
       "      <td>https://bugwoodcloud.org/images/384x256/562780...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class                                              image\n",
       "0      katydid  https://bugwoodcloud.org/images/384x256/900902...\n",
       "1      katydid  https://bugwoodcloud.org/images/384x256/900902...\n",
       "2      katydid  https://bugwoodcloud.org/images/384x256/900900...\n",
       "3  grasshopper  https://bugwoodcloud.org/images/384x256/562780...\n",
       "4  grasshopper  https://bugwoodcloud.org/images/384x256/562780..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique = df.drop_duplicates(subset='image')\n",
    "df_filtered = df_unique[df_unique['class'].isin([\"grasshopper\", \"cricket\", 'katydid'])]\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "451c8390-0d4d-4e0e-833d-3c17a9b531f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "df_filtered.to_csv('pickle.csv', index=False)\n",
    "print(\"Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eae3edec-3d07-472e-8d0c-6d421a017522",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = pd.read_csv('pickle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23d14409-96a0-4698-848d-8ef57888a860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "grasshopper    1093\n",
       "cricket         271\n",
       "katydid         155\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9075eeb3-1c16-476b-99ae-92ce2a798bef",
   "metadata": {},
   "source": [
    "Next we are going to download these images into their respective directories based on their class names. Before we donload them we want to make sure that they are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e95748e4-d3ec-4409-9cff-f27a51dcf338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "cricket        155\n",
       "grasshopper    155\n",
       "katydid        155\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_size = df_filtered['class'].value_counts().min()\n",
    "df_balanced = df_filtered.groupby('class').apply(lambda x: x.sample(min_size)).reset_index(drop=True)\n",
    "df_balanced['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9feb2062-9543-47ae-abb6-0273c3faeacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"dataset\"\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "for class_ in [\"grasshopper\", \"cricket\", 'katydid']:\n",
    "    class_dir = os.path.join(base_dir, class_)\n",
    "    if not os.path.exists(class_dir):\n",
    "        os.mkdir(class_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36325b-2c7f-49f6-9ce4-3e09113e40c3",
   "metadata": {},
   "source": [
    "We are going to use the `ThreadPoolExecutor` from `concurrent.futures` to do multi-processing in downloading and saving the images concurrently. First let's check the number of `cpu's` that are in this computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3eea560-79cf-4b56-b68e-916962d6ec5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPUs: 12\n"
     ]
    }
   ],
   "source": [
    "num_workers = multiprocessing.cpu_count()\n",
    "print(\"CPUs: {}\".format(num_workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc2b842-003b-4504-b107-16e625ed6ec5",
   "metadata": {},
   "source": [
    "We can try to get the images and their classes from a pandas dataframe to a python list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22054f72-546e-44ee-b554-355f40bbddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_urls = list(zip(\n",
    "    df_balanced['class'].values,\n",
    "    df_balanced['image'].values,\n",
    "))\n",
    "\n",
    "random.shuffle(img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "17e24058-4b75-48f0-b7b0-d98ca6dfa70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('grasshopper', 'https://bugwoodcloud.org/images/384x256/5552856.jpg'),\n",
       " ('katydid', 'https://bugwoodcloud.org/images/384x256/5178032.jpg')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_urls[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e7436-6157-480f-a4ad-11df9c7ac1f1",
   "metadata": {},
   "source": [
    "The following function save a single image of an insect in it's respective folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "498ffcfa-8ed0-427f-a71f-163d1f522040",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped = list()\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "}\n",
    "\n",
    "def save_image(row):\n",
    "    class_, url = row\n",
    "    try:\n",
    "        image_name = f\"{url.split('/')[-1]}\"\n",
    "        res = requests.get(url, headers=headers)\n",
    "        if res.status_code == 200:\n",
    "            save_name = os.path.join(base_dir, class_, image_name)\n",
    "            with open(save_name, 'wb') as fp:\n",
    "                fp.write(res.content)\n",
    "        else:\n",
    "            print(\"Failed to download the image: STATUS CODE {}\".format(res.status_code))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"url skipped:\", url)\n",
    "        skipped.append(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8bdb26-cf63-4d9d-af2e-cee611430639",
   "metadata": {},
   "source": [
    "Next we are going to download the images from the urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2a7f68b-a19a-4b15-b69c-93bddc50a87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading...: 100%|████████████████████████████████████████████████████████████████| 465/465 [05:32<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    futures = [executor.submit(save_image, i) for i in img_urls]\n",
    "    for future in tqdm.tqdm(as_completed(futures), desc=\"downloading...\", total=len(img_urls)):\n",
    "        pass\n",
    "print(\"Done!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20423d-b42f-4987-bb79-a3c573c240a0",
   "metadata": {},
   "source": [
    "After downloading these images, We want to split our dataset into `2` sets the `train` and `test`. So we are going to create the following folder structure in our `dataset` directory.\n",
    "\n",
    "\n",
    "```\n",
    "📁 dataset\n",
    "    📁  train\n",
    "      📁class_1\n",
    "         - 0.jpg\n",
    "         - 1.jpg\n",
    "         ....\n",
    "      📁  class_2\n",
    "         - 0.jpg\n",
    "         - 1.jpg\n",
    "         ....\n",
    "      .....\n",
    "    📁  test\n",
    "      📁  class_1\n",
    "         - 0.jpg\n",
    "         - 1.jpg\n",
    "         ....\n",
    "      📁  class_2\n",
    "         - 0.jpg\n",
    "         - 1.jpg\n",
    "         ....\n",
    "    ....\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ba53fcf-3491-4f66-9006-b859cdbff013",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_ in [\"grasshopper\", \"cricket\", 'katydid']:\n",
    "    train_dir = os.path.join(base_dir,'train', class_)\n",
    "    test_dir = os.path.join(base_dir,'test', class_)\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152dc375-270c-4f82-ab76-d788a80863cf",
   "metadata": {},
   "source": [
    "We will take the first `55` images and put them in the test folder to the respective class and the rest will be taken to the train folder of the respective class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c26431e-7ae8-464e-ac22-31a20f41a4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "moving images to the grasshopper folder...: 100%|█████████████████████████████████████| 55/55 [00:00<00:00, 237.71it/s]\n",
      "moving images to the grasshopper folder...: 100%|███████████████████████████████████| 100/100 [00:00<00:00, 588.21it/s]\n",
      "moving images to the cricket folder...: 100%|█████████████████████████████████████████| 55/55 [00:00<00:00, 640.25it/s]\n",
      "moving images to the cricket folder...: 100%|███████████████████████████████████████| 100/100 [00:00<00:00, 632.88it/s]\n",
      "moving images to the katydid folder...: 100%|█████████████████████████████████████████| 55/55 [00:00<00:00, 768.33it/s]\n",
      "moving images to the katydid folder...: 100%|███████████████████████████████████████| 100/100 [00:00<00:00, 653.60it/s]\n"
     ]
    }
   ],
   "source": [
    "def move_to_final_destination(trg, class_:str, limit=None):\n",
    "    class_dir = os.path.join(base_dir, class_)\n",
    "    total = len(os.listdir(class_dir)) if limit is None else limit\n",
    "    if limit is None:\n",
    "        for image_name in tqdm.tqdm(os.listdir(class_dir), total=total, desc=f\"moving images to the {class_} folder...\"):\n",
    "            src = os.path.join(class_dir, image_name)\n",
    "            shutil.move(src, trg)\n",
    "    else:\n",
    "        for image_name in tqdm.tqdm(os.listdir(class_dir)[:limit], total=total, desc=f\"moving images to the {class_} folder...\"):\n",
    "            src = os.path.join(class_dir, image_name)\n",
    "            shutil.move(src, trg)\n",
    "\n",
    "for class_ in [\"grasshopper\", \"cricket\", 'katydid']:\n",
    "    train_dir = os.path.join(base_dir,'train', class_)\n",
    "    test_dir = os.path.join(base_dir,'test', class_)\n",
    "    move_to_final_destination(test_dir, class_, limit=55)\n",
    "    move_to_final_destination(train_dir, class_, limit=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29108233-6e41-48a3-8e94-001ad139c54d",
   "metadata": {},
   "source": [
    "Next we are going to remove the `class` directories from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c0d68fa-a756-43a1-954f-c3cf6a3b688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_ in [\"grasshopper\", \"cricket\", 'katydid']:\n",
    "    _dir = os.path.join(base_dir, class_)\n",
    "    shutil.rmtree(_dir, 0o777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e38000-ee75-4a8d-a313-cbfaa062f2f8",
   "metadata": {},
   "source": [
    "### Refs\n",
    "1. [github.com/CrispenGari](https://github.com/CrispenGari/web-scrapping-python/blob/main/selenium/selenium.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
